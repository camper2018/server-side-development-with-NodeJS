JavaScript, when it is first designed was meant to be a scripting language to be used within the browser.
Now JavaScript has gone way beyond its original intention, and is being used for writing applications, both to be run using frameworks within the browser,
and also to run applications on the server side.
JavaScript originally was never designed with any common libraries.
If you look at standard programming languages like C, C++, Java, and so on,
they all have standard libraries that enable you to access the underlying hardware.
And also provide a structured way of organization the application into multiple files and then combining them together when you create an application.
JavaScript never had any of this support when it began.
But of course, people understood the difficulties when you need to expand JavaScript beyond a single file which is used as a scripting language for the browser.
Now, if you have a very large JavaScript application, it becomes cumbersome to write the entire code in one single file.
And obviously you want the results to be able to break your application into multiple facts.
Unlike traditional programming languages, JavaScript never had a way of distributing the code into multiple files and then combining them together.
So this is where the CommonJS API came in to fill in this gap that fills in the needs for some common application.
And this CommonJS format defines a module format that can be used for breaking up your JavaScript application into multiple files.
Node adopts that CommonJS format for organizing our JavaScript application into multiple files.
And within JavaScript, with the CommonJS format, each file becomes its own Node module.
So within that file, the CommonJS specification provides a variable called the module variable which is a JavaScript object.
And this gives you access to the current module definition within a file.
And on this module object, you have the module.exports property which determines the export from the current module.
So when you assign something to the module.exports property, then that becomes the exported value from the current module.
So that when this module is imported into another file of our Node application, then whatever is exported from this module becomes available in the second application.
When you need to import a module into another module, this is where the require function is used to import the module.
Node modules can be of three kinds:
1. We have file-based Node modules where we define the Node module within a file, within our application and we make use of it within our application.
2. We have core Node modules that are already part of Node.
The Node designers kept these core modules intentionally small so that Node can be kept small.
And also provide sufficient functionality so that external module designers can add in their own functionality that can be leveraged when we developed Node applications.
So the core modules include path, file system (fs), os, util, and a few others.
3. Then we have external Node modules.
These are third-party Node modules that are developed by Node developers, and then made available through the Node ecosystem.
So these external Node modules can be install within our system using NPM.

Package.json is a Menifest file for our app. It is a file that contains information about the files in our app i.e metadata eg: name, version, liscence, author, modules used etc
With node, we have the option of using JavaScript or Typescript as a language.
The documentation for node and also express, all use standard JavaScript as a default. So we will be using standard JavaScript in this course or ES2015 JavaScript in this course.
If we prefer to use TypeScript, we can set up our node examples to write our application in TypeScript.
But then we will have to transpile that code into JavaScript so that it can be run using Node.
So we have to set up additional infrastructure in order to be able to use TypeScript.
Asynchronous execution and Callbacks:
Before we proceed on to talk about Node Modules and Callbacks, we need to understand two salient features about the JavaScript language itself.
First and foremost, JavaScript supports what is called as first-class functions.
Is that a function can be treated just like any other variable.
And hence, functions can be passed around as parameters inside function calls to other functions.
And that essentially allows us to send in functions as callback functions that can be called from another Node module in order to get some work accomplished.
Then look at how this is very useful in supporting callbacks in Node.js
The second aspect about JavaScript is the support for Closures.
A function defined inside another function automatically gets access to the variables that are declared in the outer function. So even if the outer function is completed execution, when the inner function executes later the inner function will still have access to the values of the variables within that outer function.
And this is again, very effectively used when we use Callbacks in Node applications.

HTTP VERBS:
Http is a client-server communication protocol.
Get, Post, Put, Delete, Head, Options, Trace, Connect.

Intro To Express:
The Node designers intentionally kept node small with a small number of code modules so that they can leave it up to third party developers to come up with innovative solutions to problems.
One of the most popular third party Node modules or frameworks for building HTTP servers is Express.
Express is a fast, unopinionated, minimalist framework that runs on top of Node.js and supports Web development.
Express also provides a way of extending and adding functionality to Express through third-party middleware.
To use Express in your project, of course, the first step is to install Express and since Express is a Node module, we install it by saying npm install express --save and this would install Express into your local project.
The middleware that Express supports provide a lot of plug-in functionality that would be used to enhance your Express application,
plug-in functionality like for example we will look at a middleware called Morgan which allows you to print out log information to the screen about the requests that come into your server.
Similarly, we'll look at another middleware called BodyParser, which allows you to parse the body of the incoming HTTP request message and extract information from it for use within your Express application.
Similarly, they can serve up static Web resources from our server using the express.static so this will serve up information from a folder within our Express project,
and in declaring the project we can say __filename and __dirname which gives you the full path for the file or the directory for the current module.
Brief Tour of a Node Module:
Examine a Package.json file and look at semantic versioning.
So when you specify the version of the package that you use, you always specify the version by specifying the Major Version.Minor Version.the patch.
So when you install a package, it is always identified by these three numbers:
major version which might introduce breaking changes so which means that if you are installing a newer version of package it may not be completely backward compatible with previous versions.
It may introduce breaking changes whereby you may need to go back and fix the code that you might have written in the earlier version of your project.
The minor version introduces some minor changes to your package and may not be breaking changes.
A patch would be a bug fix that is often issued when a small bug is discovered.
So patches usually do not lead to any breaking changes and so you can easily use a higher version or a higher patch version of a particular package that you're using within your Node application.
With npm install, we can specifiy the acceptable package version as follows:
1.Exact: means exact version match : npm install express@4.0.0
2.Patch acceptable: npm install express@"~4.0.0"
3.Minor version acceptable:npm install express@"^4.0.0"
This kind of information is also saved in the package.json file.
The third-party modules and their version info is stored in package.json file in as dependencies.

Package.lock.json file:
This is being installed by the newer versions of npm.
The package-lock.json file is automatically generated by npm which stores information about the exact tree that was generated when you install other Node modules
and this is very useful when you need to do installation of the Node modules at another location.
So for example if you download a Git repository and try to recreate this project on another computer, you would simply type npm install on the prompt and that'll prompt your Node application to automatically install everything that is specified in the dependencies here for you.
While creating that the package-lock.json stores additional information that is used by npm to do the correct installation of all the npm modules that are required.

Exercise (Instructions): Introduction to Express:
In this exercise you learnt to use the Express framework to design and implement a web server.
a.A Simple Server using Express:
1.Create a folder named node-express in the NodeJS folder and move to that folder.
2.Copy the public folder from node-http to this folder.
3.At the prompt, type the following to initialize a package.json file in the node-express folder:
npm init
4.Accept the standard defaults suggested until you end up with a package.json file as we have in folder.
5.Then, install the Express framework in the folder by typing the following at the prompt:
  npm install express@4.16.3 --save
6.Create a file named .gitignore and add the following to it:
  node_modules
7.Create a file named index.js and add the code to it as seen in commit "Express Example".
8.Start the server by typing the following at the prompt, and then interact with the server:
  npm start
9.Initialize a Git repository, add the files and do a Git commit with the message "Express Example".

b.Serving Static Files:
1.Install morgan by typing the following at the prompt. Morgan is used for logging purposes:
  npm install morgan@1.9.0 --save
2.Update index.js to include it.
3.Start the server and interact with it and observe the behavior.
4.Do a Git commit with the message "Express Serve Static Files".

REST:
Web Services are a way of designing systems to support interoperability among systems that are connected over a network like the internet as we see today.
This is what we refer to as a service-oriented architecture.
Now, what this means is that you provide a standardized way for two machines that are connected to the internet to be able to communicate with each other at the application layer level for web-based applications using open standards.
Two common approaches that are used for supporting web services are:
1. SOAP: The Simple Object Access Protocol based web services which uses the web services description language for specifying how the two endpoints communicate with each other.
Typically SOAP is based on using XML as the format for the messages being exchanged between the two endpoints.
2.Representational State Transfer or REST also uses web standards, but the exchange of data between the two endpoints could be either XML or increasingly using JSON as the format.
The REST way of interoperability is simpler compared to SOAP and hence, REST has found a lot wider deployment in the web services world.
Typically, client-server communication is facilitated using REST where the server supports a REST API and the client can then invoke the REST API endpoints in order to obtain information or to upload information to the server.
Within Representational State Transfer, there are four basic design principles:
1. First and foremost, REST is built upon HTTP protocol, so it uses all the HTTP methods.
2. Second, REST is designed to be stateless, meaning that the server doesn't store any information about the state after the communication is completed.
3. Third, the REST way of providing resources is to expose a directory structure like URLs (Uniform Resource Locators - URLs).
4. Fourth, the format for data exchange is typically JSON or XML or both can be supported using REST.
In the REST world you often hear people talking about nouns, verbs, and representations.
1. Nouns specifically refer to resources and these resources are usually identified by their URLs and these are unconstrained.
  Now, these resources can be organized into a hierarchy of the specification of this URI.
  So, as we traverse the path, we go from the more general to the more specific of the resource.
  This directory structure enables you to identify the resources that you use or provide from your server-side very easily.
2. Verbs are constraint and these specify the actions to be done on the resources.
   GET, POST, PUT and DELETE, are mapped into the four CRUD operations that we can carry out on a database that stores these resources on the server-side,
   the READ, CREATE, UPDATE, and DELETE operations.
3. Representsation is, when the information needs to be conveyed from the server to the client or from the client to the server, how you encode the information.
  Typically, either using JSON or using XML.

DELETE operation would be idempotent because if you try to delete a resource and the resource exists, it will be deleted.
If you are trying to delete a non-existing resource, it won't cause any further modification to the server-side, except that the server will reply with an error saying that the resource doesn't exist.
Similarly, the GET operation is also an idempotent operation because it is not making any modifications to the resource on the server-side.
POST and PUT of course are going to modify the resource on the server-side, either create a new resource or modify an existing resource on the server-side.
Each endpoint is identified by a URI, and we can specify the various operations to be done on each endpoint using the appropriate HTTP verb, the GET, PUT, POST, or DELETE.
The last part that we need to emphasize is that server-side should be completely stateless,
which means that the server-side does not track the client state because if the server needs to track the clients state, it will not be scalable.
So, for a scalable implementation of the server-side, you normally use a stateless server on the server-side.
So, every request that the client sends to the server will be treated as an independent request and will not reflect upon previous requests that have already been handled by the server from that particular client.
So, it's the responsibility of the client to track its own state, either in the form of using cookies or using a client-side database, whatever means that is suitable.
Now, this approach where the client tracks its own state is a lot more scalable because each individual client will be responsible for tracking its own state.
This is where the client-side MVC setup helps us in this regard.

EXPRESS ROUTER:
If you are implementing an Express application which supports multiple REST API endpoints,
then it makes sense to subdivide the code into multiple modules and then make use of them to construct the overall Express application.
So this where the Express router comes to our aid.
Express router enables us to subdivide our application and organize it into multiple mini Express-like applications, which combine together to form the Express application.
An Express router defines many Express application, and within that many Express application,
you can, for example, deal with one particular REST API endpoint in more detail, or one particular pattern of REST API endpoint in more detail.

Exercise (Instructions): Express Router:
In this exercise, we used the Express framework and Express router to build a server supporting a REST API.

Setting up a REST API:
1.You will continue in the node-express folder and modify the server in this exercise.
2.Install body-parser by typing the following at the command prompt:
     npm install body-parser@1.18.3 --save
3.Update index.js to add /dishes and /dishes:dishId REST api endpoints.
4.Start the server and interact with it from the browser/postman.
5.Do a Git commit with the message "Express Simple REST Api".

Using Express Router:
1.Create a new folder named routes in the node-express folder.
2.Create a new file named dishRouter.js in the routes folder and add the code to implement /dishes route.
3.Update index.js to use dishesRouter module within the main express app.
4.Start the server and interact with it and see the result.
5.Do a Git commit with the message "Express Router".

Assignment 1:
In this assignment we will continue the exploration of Node modules, Express and the REST API.
We will implement /dishes/:dishId endpoint in the dishRouter.
We will design two new express routers to support REST API end points for promotions and leadership.

Step-By-Step Assignment Instructions:

Assignment Overview:
At the end of this assignment, you should have completed the following tasks to update the server:

1. Created a Node module using Express router to support the routes for the dishes REST API.
2. Created a Node module using Express router to support the routes for the promotions REST API.
3. Created a Node module using Express router to support the routes for the leaders REST API.

Assignment Requirements:
The REST API for our React application that we built in the previous courses requires us to support the following REST API end points:

http://localhost:3000/dishes/:dishId
http://localhost:3000/promotions and http://localhost:3000/promotions/:promoId
http://localhost:3000/leaders and http://localhost:3000/leaders/:leaderId
We need to support GET, PUT, POST and DELETE operations on each of the endpoints mentioned above, including supporting the use of route parameters to identify a specific promotion and leader.
We have already constructed the REST API for the dishes route in the previous exercise.
This assignment requires you to complete the following three tasks. Detailed instructions for each task are given below.

Task 1
In this task you will create a separate Node module implementing an Express router to support the REST API for the dishes.
You can reuse all the code that you implemented in the previous exercise. To do this, you need to complete the following:
Update the Node module named dishRouter.js to implements the Express router for the /dishes/:dishId REST API end point.

Task 2
In this task you will create a separate Node module implementing an Express router to support the REST API for the promotions.
To do this, you need to complete the following:
Create a Node module named promoRouter.js that implements the Express router for the /promotions and /promotions/:promoId REST API end points.
Require the Node module you create above within your Express application and mount it on the /promotions route.

Task 3
In this task you will create a separate Node module implementing an Express router to support the REST API for the leaders.
To do this, you need to complete the following:

Create a Node module named leaderRouter.js that implements the Express router for the /leaders  and /leaders/:leaderId REST API end points.
Require the Node module you create above within your Express application and mount it on the /leaders route.

Express Generator:
Express Generator is a quick scaffolding tool that will help us to quickly build up the structure for an Express application with some starting code already built and some standard middleware already included into the application.
And so all that we need to do is install the Express Generator via Command line interface as a global NPM module, and then use that to scaffold out our Express application.
sudo npm install express-generator -g
moved into the node-express folder
Then type express <app-name> i.e express conFusionServer
And this will generate a folder with the name of the application that you have typed in.
There are various options available for you to generate your Express application.
It can use different kinds of view generators like jade, EJS, and so on.
In this course, we will be using Express purely as a server that supports REST API.
And once you scaffold out your Express application, you just move into the application folder
and do an npm install to install all the preconfigured modules that are already included in your default Express application.

Exercise (Instructions): Express Generator:
Objectives and Outcomes
In this exercise, you will use the Express generator to scaffold out an Express application. Thereafter you will modify the application to support REST API making use of the Node modules that you developed as part of the first assignment. At the end of this exercise, you will be able to:

Generating an Express application using the express-generator
Modify the Express application to support the REST API by adding routes

Installing express-generator
1.Install express-generator by typing the following at the prompt:
  sudo npm install express-generator@4.16.0 -g
2.To scaffold out an Express application, type the following at the prompt:
  express conFusionServer
3.Next, move to the conFusionServer folder. Type the following at the command prompt to install all the Node modules:
  npm install
4.You can start the Express server by typing the following at the prompt:
  npm start
5.Add a file named .gitignore to the project folder and type the following into the file:
  node_modules
6.Initialize a Git repository and do a Git commit with the message "Express Generator".

Implementing a REST API
1. Now, copy the dishRouter.js, promoRouter.js and leaderRouter.js from your first assignment (node-express/routes folder) to the routes folder within the Express application that you just scaffolded out.
2. Furthermore, copy the index.html and aboutus.html file from the node-express/public folder to the public folder in your new project.
3. Then, open the app.js file and then update the code in there
4. Save the changes and run the server. You can then test the server by sending requests and observing the behavior.
5. Do a Git commit with the message "Express Generator REST API".

MongoDB:
The NoSQL databases themselves can be classified into four different categories:
1.document based databases like MongoDB
2. key value based databases like Redis
3. column-family-based databases like Cassandra
4. graph databases like Neo4J
A document is a self-contained unit of information
and can be in many different formats,
JSON being one of the most popular formats for storing documents in a document database.
Documents themselves can be organized into collections.
So a collection is a group of documents and in turn, the database itself can be considered as a set of collections.
The document in MongoDB is nothing but a JSON document.
In fact, MongoDB stores the document in a more compact form called as the BSON format or binary JSON format.
Every document in MongoDB database must have an ID field, an _id field, which acts as the primary key for the document.
And this field is unique for each document.
The ID field itself can be used in many formats and one particular format that MongoDB automatically assigns in case you don't choose to use your own ID field is the object ID that is created by default by MongoDB.
The object ID field itself is a 12 byte field.
The first four bytes includes a timestamp, the typical Unix timestamp in the resolution of a second.
Then the next three bytes towards the machine ID, the machine on which the Mongo server is running.
and the next two bytes is the process ID, the specific Mongo process which has created this document
and then the last field is an increment(self-incrementing).
When given an ID, you can easily retrieve information from this ID.
For example, you can get hold of the ObjectID and then call the getTimestamp method of the object ID
and this will return the timestamp in the ISO date format.
So that will enable you to identify when this document has been created.

Exercise (Instructions): Introduction to MongoDB:
Objectives and Outcomes
a.Download and Installing MongoDB
b.Start the server and interact with it using the Mongo REPL shell

1.Go to http://www.mongodb.org, then download and install MongoDB as per the instructions given there.
2.Create a folder named mongodb on your computer and create a subfolder under it named data.
3.Move to the mongodb folder and then start the MongoDB server by typing the following at the prompt:
   mongod --dbpath=data --bind_ip 127.0.0.1
   We created q data subfolder inside the mongodb folder.
   So the dbpath here essentially takes the path to the folder, which will store the data for my Mongo application.
   We can execute this mongod command from any location on our computer ss long as we specify the complete path to the location of the data folder where our MongoDB data is going to be stored.
   Since we are running mongod server already in the mongodb folder, and the data folder is a sub-folder of the mongodb folder,
   we can just simply execute the command by saying mongodb -- dbpath=data.

4.Open another command window and then type the following at the command prompt to start the mongo REPL shell:
   mongo
5.The Mongo REPL shell(read evaluate print loop) will start running and give you a prompt to issue commands to the MongoDB server. At the Mongo REPL prompt, type the following commands one by one and see the resulting behavior:
  db
  use conFusion
  db
  db.help()
6.You will now create a collection named dishes, and insert a new dish document in the collection:
  db.dishes.insert({ name: "Uthappizza", description: "Test" });
7.Then to print out the dishes in the collection, type:
  db.dishes.find().pretty();
8.Next, we will learn the information encoded into the ObjectId by typing the following at the prompt:
  var id = new ObjectId();
  id.getTimestamp();
9.Type "exit" at the REPL prompt to exit the Mongo REPL.

Node and MongoDB:
Node MongoDB Driver module provides a high-level API that enables us to access the Mongo server from within our Node application.
It provides you with many methods that enable you to interact with your Mongo server.
It allows you to perform various database operations like inserting, deleting and updating an existing record or adding new records to your database.
Also, it provides various ways of querying the documents that are already within the database.
The driver itself supports both callback based and promise based interactions with the MongoDB server.

Exercise (Instructions): Node and MongoDB Part 1:
Objectives and Outcomes:
In this exercise you will install the Node MongoDB driver module and configure your Node application to communicate with the MongoDB server. At the end of this exercise, you will be able to:

Install and use the Node MongoDB driver
Interact with the MongoDB database from a Node application

Installing the Node MongoDB Driver Module
1.Create a new folder named node-mongo and move into the folder.
2.At the prompt, type the following to initialize a package.json file in the node-mongo folder:
  npm init
3.Accept the standard defaults suggested until you end up with a package.json file.
4.Install the Node MongoDB driver and the Assert module by typing the following at the prompt:
  npm install mongodb@3.0.10 --save
  npm install assert@1.4.1 --save

A Simple Node-MongoDB Application
1.Create a new file named index.js and add code in it.
2.Make sure that your MongoDB server is up and running
3.Type the following at the prompt to start the server and see the result.
  npm start
4.Add a .gitignore file with the contents "node_modules" in the project folder.
5.Initialize the Git repository, check in all the files and do a Git commit with the message "Node MongoDB Example 1".

Exercise (Instructions): Node and MongoDB Part 2
Objectives and Outcomes
In this exercise you will continue to explore communicating from our Node application to the MongoDB server.
At the end of this exercise you will be able to:
1.Develop your own Node module (file based module) containing some common MongoDB operations
2.Use the Node module in your application and communicate with the MongoDB server

Implementing a Node Module of Database Operations:
1.Create a new file named operations.js that contains a few MongoDB operations and add the code

Using the Node Module for Database Operations
1.Update the file named index.js
2/Run the server by typing the following at the prompt and observe the results:
  npm start
3.Do a Git commit with the message "Node MongoDB Example 2".
Conclusions
In this exercise you created a Node module to package some database operations,
and then used the module to interact with the MongoDB server.

Callback Hell and Promises:
Heavily nested callback code, causes the Callback Hell problem and it results from our tendency to write programs top-down.
We are still hung up with our sequential way of writing code and so we see it more convenient to write code top to bottom, and look at it as if it is executing in that order.
Now we can work around the Callback Hell problem by not using anonymous functions for the callbacks but instead, declaring those functions with specific names, and then avoid the way we write the code as you saw here.
That is one of the approaches that people take to deal with the Callback Hell problem.
Another approach that is used to deal with for the Callback Hell problem,is the use of promises.

A promise is a mechanism that supports asynchronous computation.
So if you have amount of work that needs to be done, the promise acts as a proxy for a value which is not known at the moment but the promise is given to you.
But when the value becomes available, it will be available in the future.
So the promise represents a placeholder for that value.
If the value results correctly, then your promise results correctly and you can have a piece of code executed in order to handle the fact that the promise resolved correctly,
if not then you handle the error in that situation.
So, a promise will resolve either into resolve or the rejection of the promise.

The node MongoDB driver natively supports promises.
So, if you do not specify a callback, the calls to their functions will return promises.
So, we're going to update our application to make use of promises to avoid the callback hell issue
Exercise (Instructions): Callback Hell and Promises:
Objectives and Outcomes
In this exercise you will learn to use promise support to update the Node application to avoid callback hell.
Using Promises
1.Update operations.js
2.Next open index.js and update it
3.Run the node application and see the result
4.Do a Git commit with the message "Node Callback Hell and Promises".

Mongoose ODM
We learned how the node MongoDB driver enables our node application to communicate with a MongoDB server.
When the documents are stored in the database, the MongoDB driver itself imposes no structure on the documents.
Any document can be stored in any collection.We can easily insert documents that don't necessarily comply with the structure.
MongoDB relies on the developer to enforce the structure on the documents,
and gives the complete responsibility to the developer to make sure that documents of the correct structure are added and maintained in the various collections.
If we are very particular that the structure of the documents in a collection always have a specified structure, and always will have the specific set of fields,
then the MongoDB itself doesn't impose that neither does the node MongoDB driver that we have seen in the previous lesson.
his is where we will need a more formal way of imposing structure on the documents that are stored in a collection in a MongoDB database.
his is where the Mongoose node module comes to our help.
The Mongoose node module imposes a standardized structure for the documents that are stored in a particular collection.
So, that is why we often hear people referring to this as the Mongoose ODM.
The ODM itself is interpreted by some people to mean Object Data Model or sometimes referred to as Object Document Mapping, or some people refer to it as ORM or Object Relational Mapping.
Now, when we talk about relational that applies a lot more to relational databases,
but then with SQL databases we needed explicitly the object to relational mapping to be put in between the database and our application itself.
Because within the application we would be looking at objects but their storage in an SQL database will be in the form of records, and so you need an explicit mapping.
As we saw with the NoSQL database, this was not explicitly required.
But if we need to impose structure on our documents that are stored in a collection then the use of Mongoose to impose this structure is very, very useful.
The way Mongoose goes around imposing structure on the documents is through the use of schema.
Mongoose schema, implies a structure on the data that is stored in a document in your database.
So, it defines all the fields of our document, and also specifies the types of the fields,
and also can provide us with additional features that can enable validation on these fields.
So, for example, the various schema types that are supported in Mongoose include: String, Number, Date, Buffer, Boolean, Mixed, object ID, and Array.
An array schema type would allow us to create an array of sub-documents inside the document.
Once you define a schema, the schema is then used in Mongoose to create a model function, and that is what enables you to define the structure for your documents in the database.
Schemas themselves can be nested to enable supporting embedded or subdocuments.
The sub-documents typically are accommodated either through specifying an additional schema,
and then defining one of the fields of the schema to be off the type of the other schema.
Or you can even go with an array of another schema type within a second schema that you define.
For example, if you define a schema earlier, so for example, you previously defined a commentSchema, now you can also define the comment field into another schema (e.g dishSchema) and then specify that that field will be of the type of the previous schema that you have defined i.e {coment: [commentSchema]} type.
So, an array of comments that will be included in each dish document, thereby, you can have more than one comment sub-document enclosed inside a dish document.
You can also define additinal field in your schema that is : timestamps: true
The timestamps allow you to have two different fields in the document: the created_at field and the updated_at fields, both of which are timestamps stored in the form of an ISO date string in the document.
Now, once we define the schema, to make use of this in our application, we need to create a model from that schema that we have just defined.
e.g var Dishes = mongoose.model('Dish', dishSchema);
we will define a Mongoose model and specify that the model is off the type dishSchema in this example.
when you give a name to the model here, we are specifying the name as Dish.
Now, when we use this dish model in our node application where we are making use of Mongoose, then this will be transformed and mapped into a collection in my MongoDB database i.e dishes
So, Mongoose automatically knows that when you specify a name, it'll automatically construct the plural of that name and then give the collection the name, which is the plural of the model name that you specify.
Mongoose also enables us to establish the connection with the MongoDB server.
Mongoose internally make use of the MongoDB driver that we had used in the previous exercise.
So, Mongoose depends upon the MongoDB driver,
so, which means that from your Mongoose-based node application, you can use all the methods that are already available from the MongoDB driver also if you choose to,
but Mongoose itself has its own collection of methods that we can make use of to interact with the MongoDB database.

Exercise (Instructions): Mongoose ODM Part 1
Objectives and Outcomes
In this exercise you will explore the Mongoose ODM and learn about creating schemas and interacting with the MongoDB database using Mongoose methods. At the end of this exercise, you will be able to:

Install Mongoose ODM and connect to a MongoDB Server
Create Mongoose Schemas
Perform Database operations with Mongoose methods

Installing Mongoose:
1.Create a folder named node-mongoose and move into the folder.
2.At the prompt, type the following to initialize a package.json file in the node-mongoose folder:
  npm init
3.Accept the standard defaults suggested
4.n this folder, install Mongoose by typing the following at the prompt:
  npm install mongoose@5.1.7 --save

Implementing a Node Application
1.Create a sub-folder named models in the node-mongoose folder. Move to this folder.
2.Create a file named dishes.js and add the following code to create a Mongoose schema
3.Move to the node-mongoose folder and create a file named index.js and add the code:
4.Make sure that your MongoDB server is up and running. Then at the terminal prompt type the following to start the server and see the result:
  npm start
5.Create a .gitignore file with the contents "node_modules"
6.Initialize the Git repository and do a Git commit with the message "Mongoose Part 1".

Exercise (Instructions): Mongoose ODM Part 2
Objectives and Outcomes
In this exercise you will continue to explore the Mongoose ODM and learn about creating schemas and interacting with the MongoDB database using Mongoose methods. At the end of this exercise, you will be able to:
Perform Database operations with Mongoose methods
Mongoose Operations
1.Now, update index.js
2.Run this server on the console and see the result.
3.Do a Git commit with the message "Mongoose Part 2".

Adding Sub-documents to a Document
1.Update dishes.js in the models folder
2.Update index.js
3.Run the server and observe the result.
4.Do a Git commit with the message "Mongoose Part 3".


Exercise (Instructions): REST API with Express, MongoDB and Mongoose Part 1:

Objectives and Outcomes:
In this exercise, you will integrate the REST API server based on the Express framework that you implemented earlier, together with the Mongoose schema and models to create a full-fledged REST API server. At the end of this exercise, you will be able to:
1.Develop a full-fledged REST API server with Express, MongoDB and Mongoose
2.Serve up various REST API end points together with interaction with the MongoDB server.

Update the Express Application:
1.Go to the conFusionServer folder where you had developed the REST API server using Express generator.
2.Copy the models folder from the node-mongoose folder to the conFusionServer folder.
3.Then install bluebird, mongoose and mongoose-currency Node modules by typing the following at the prompt:
  npm install mongoose@5.1.7 mongoose-currency@0.2.0 --save
  The Mongoose currency adds in support for currency in our schema
  Since our dish is going to contain a price, that is why we are going to be using the Mongoose currency module here
4.Open app.js file and add in the code to connect to the MongoDB server
5.Next open dishes.js in the models folder and update it
6.Now open dishRouter.js and update its code
7.Save the changes and start the server. Make sure your MongoDB server is up and running.
8.You can now fire up postman and then perform several operations on the REST API. You can use the data for all the dishes provided in the db.json file given above in the Exercise Resources to test your server
9.Do a Git commit with the message "Express REST API with MongoDB and Mongoose Part 1"

Exercise (Instructions): REST API with Express, MongoDB and Mongoose Part 2:
Objectives and Outcomes:
In this exercise, you will continue the integration of the REST API server based on the Express framework that you implemented earlier, together with the Mongoose schema and models to create a full-fledged REST API server.
At the end of this exercise, you will be able to:
1.Add support for accessing and updating comments within the dishes.

Handling Comments:
1.Add the code to dishRouter.js to handle comments:
2.Save the changes and start the server. Make sure your MongoDB server is up and running.
3.You can now fire up postman and then perform several operations on the REST API. You can use the data for all the dishes provided in the db.json file given above in the Exercise Resources to test your server
4.Do a Git commit with the message "Express REST API with MongoDB and Mongoose Part 2".

Assignment 2 Instructions:
In this assignment, you will continue your journey with MongoDB and Mongoose.
You will then create two new schemas for promotions and leadership,
and then extend the Express REST API server to support the /promotions and the /leaders REST API end points.

Step-By-Step Assignment Instructions

Assignment Overview:
At the end of this assignment you would have completed the following three tasks:
1.Implemented the Promotions schema and model
2.Implement a REST API to support the /promotions endpoint, and the /promotions/:promoId endpoint enabling the interaction with the MongoDB database
3.Implemented the Leaders schema and model
4.Implement a REST API to support the /leaders endpoint, and the /leaders/:leaderId endpoint enabling the interaction with the MongoDB database

Assignment Requirements:
This assignment consists of the following two tasks:
You are given the following example of a promotion document. You will now create the Promotions schema and model to support the document:
{
      "name": "Weekend Grand Buffet",
      "image": "images/buffet.png",
      "label": "New",
      "price": "19.99",
      "description": "Featuring . . .",
      "featured": false
}
Note in particular that the label and price fields should be implemented the same way as you did for the Dishes schema and model. The Promotions schema and model should be defined in a file named promotions.js.
Next, extend the promoRouter.js to enable the interaction with the MongoDB database to fetch, insert, update and delete information.

Task 2:
You are given the following example of a leadership document. You will now create the Leaders schema and model to support the document:

{
      "name": "Peter Pan",
      "image": "images/alberto.png",
      "designation": "Chief Epicurious Officer",
      "abbr": "CEO",
      "description": "Our CEO, Peter, . . .",
      "featured": false
}

The Leaders schema and model should be defined in a file named leaders.js.
Next, extend the leaderRouter.js to enable the interaction with the MongoDB database to fetch, insert, update and delete information.


